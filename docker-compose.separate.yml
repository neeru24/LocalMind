version: '3.8'

# Alternative docker-compose configuration with separate backend and frontend services
# Use this if you want to scale services independently

services:
  # Backend API service
  backend:
    build:
      context: ./LocalMind-Backend
      dockerfile: Dockerfile
    image: localmind-backend:latest
    container_name: localmind-backend
    restart: unless-stopped
    ports:
      - '3000:3000'
    environment:
      # Application Settings
      - NODE_ENV=production
      - PORT=3000
      - APP_ENV=production
      - ENVIRONMENT=production

      # Security
      - LOCALMIND_SECRET=${LOCALMIND_SECRET:-your-secret-key-change-me}
      - JWT_SECRET=${JWT_SECRET:-${LOCALMIND_SECRET:-your-secret-key-change-me}}

      # API Keys (Optional - for cloud providers)
      - API_KEY=${API_KEY:-}
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - GEMINI_API_KEY=${GEMINI_API_KEY:-}
      - GOOGLE_API_KEY=${GOOGLE_API_KEY:-}
      - GROQ_API_KEY=${GROQ_API_KEY:-}
      - ROUTERAI_API_KEY=${ROUTERAI_API_KEY:-}

      # Ollama Connection
      - OLLAMA_HOST=${OLLAMA_HOST:-http://host.docker.internal:11434}

      # Database (MongoDB)
      - DB_HOST=${DB_HOST:-localhost}
      - DB_PORT=${DB_PORT:-27017}
      - DB_NAME=${DB_NAME:-localmind}
      - DB_USER=${DB_USER:-}
      - DB_PASSWORD=${DB_PASSWORD:-}
      - DB_CONNECTION_STRING=${DB_CONNECTION_STRING:-mongodb://localhost:27017/localmind}

      # Redis (if used)
      - REDIS_HOST=${REDIS_HOST:-localhost}
      - REDIS_PORT=${REDIS_PORT:-6379}
      - REDIS_PASSWORD=${REDIS_PASSWORD:-}

      # Other required env vars
      - Your_Name=${Your_Name:-LocalMind}
      - YOUR_EMAIL=${YOUR_EMAIL:-admin@localmind.local}
      - YOUR_PASSWORD=${YOUR_PASSWORD:-changeme}
      - ENCRYPTION_KEY=${ENCRYPTION_KEY:-${LOCALMIND_SECRET:-your-secret-key-change-me}}
      - SERVER_HMAC_SECRET=${SERVER_HMAC_SECRET:-${LOCALMIND_SECRET:-your-secret-key-change-me}}
      - UPLOAD_DIR=${UPLOAD_DIR:-/app/uploads}
      - TEMP_DIR=${TEMP_DIR:-/tmp}
      - MAX_FILE_SIZE=${MAX_FILE_SIZE:-10485760}
      - LOG_LEVEL=${LOG_LEVEL:-info}
      - DEBUG=${DEBUG:-false}
      - CORS_ENABLED=${CORS_ENABLED:-true}
      - RATE_LIMIT_ENABLED=${RATE_LIMIT_ENABLED:-false}
      - ENABLE_RATE_LIMITING=${ENABLE_RATE_LIMITING:-false}
      - JWT_EXPIRATION=${JWT_EXPIRATION:-7d}
      - BACKEND_URL=${BACKEND_URL:-http://backend:3000}

    volumes:
      - localmind-uploads:/app/uploads
      - localmind-data:/app/data

    networks:
      - localmind-network

    healthcheck:
      test: ['CMD', 'node', '-e', "require('http').get('http://localhost:3000/', (r) => {process.exit(r.statusCode === 200 ? 0 : 1)})"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Frontend service
  frontend:
    build:
      context: ./LocalMind-Frontend
      dockerfile: Dockerfile
    image: localmind-frontend:latest
    container_name: localmind-frontend
    restart: unless-stopped
    ports:
      - '80:80'
    depends_on:
      - backend
    networks:
      - localmind-network
    healthcheck:
      test: ['CMD', 'wget', '--quiet', '--tries=1', '--spider', 'http://localhost/']
      interval: 30s
      timeout: 10s
      retries: 3

  # Optional: Run Ollama in Docker
  # ollama:
  #   image: ollama/ollama:latest
  #   container_name: localmind-ollama
  #   restart: unless-stopped
  #   ports:
  #     - "11434:11434"
  #   volumes:
  #     - ollama-models:/root/.ollama
  #   networks:
  #     - localmind-network

networks:
  localmind-network:
    driver: bridge

volumes:
  localmind-uploads:
    driver: local
  localmind-data:
    driver: local
  # ollama-models:
  #   driver: local

