<div align="center">
  <img src="assets/Banner_LocalMind.png" alt="LocalMind Banner" width="900"/>
  <br/><br/>
  <h1><b>LocalMind â€” AI Without Limits</b></h1>
  <p>
    A free, open-source AI platform that lets you run local LLMs, connect cloud AI providers, teach your AI with your own data, and share your AI instance globally â€” all with full privacy and unlimited usage.
  </p>
  <br/>

  <!-- Badges -->
  <a href="https://opensource.org/licenses/MIT">
    <img src="https://img.shields.io/badge/License-MIT-blue.svg" alt="MIT License"/>
  </a>
  <a href="https://www.typescriptlang.org/">
    <img src="https://img.shields.io/badge/TypeScript-3178C6?logo=typescript&logoColor=white" alt="TypeScript"/>
  </a>
  <a href="https://reactjs.org/">
    <img src="https://img.shields.io/badge/React-61DAFB?logo=react&logoColor=black" alt="React"/>
  </a>
  <a href="https://nodejs.org/">
    <img src="https://img.shields.io/badge/Node.js-339933?logo=node.js&logoColor=white" alt="Node.js"/>
  </a>
  <a href="https://expressjs.com/">
    <img src="https://img.shields.io/badge/Express-000000?logo=express&logoColor=white" alt="Express"/>
  </a>
  
  <br/><br/>
  
  <p>
    <a href="#-quick-start">Quick Start</a> â€¢
    <a href="#-features">Features</a> â€¢
    <a href="#-installation-guide">Installation</a> â€¢
    <a href="#-api-documentation">API Docs</a> â€¢
    <a href="#-contributing">Contributing</a>
  </p>
</div>

---

## ğŸ“– Table of Contents

- [ğŸ”¥ Overview](#-overview)
- [âœ¨ Features](#-features)
  - [ğŸ§  AI Model Support](#-ai-model-support)
  - [ğŸ“š RAG: Train with Your Own Data](#-rag-train-with-your-own-data)
  - [ğŸŒ Global AI Sharing](#-global-ai-sharing)
  - [ğŸ”’ Privacy & Security](#-privacy--security)
- [ğŸš€ Quick Start](#-quick-start)
- [ğŸ“¦ Installation Guide](#-installation-guide)
  - [Prerequisites](#prerequisites)
  - [Backend Setup](#1-backend-setup)
  - [Frontend Setup](#2-frontend-setup)
  - [Running with Docker](#3-docker-optional)
- [âš™ï¸ Configuration](#ï¸-configuration)
- [ğŸ“ Project Structure](#-project-structure)
- [ğŸ§© API Documentation](#-api-documentation)
- [ğŸ’¡ Usage Examples](#-usage-examples)
- [ğŸ› ï¸ Tech Stack](#ï¸-tech-stack)
- [ğŸ”§ Troubleshooting](#-troubleshooting)
- [ğŸ—ºï¸ Roadmap](#ï¸-roadmap)
- [ğŸ¤ Contributing](#-contributing)
- [ğŸ“„ License](#-license)
- [ğŸ™ Acknowledgments](#-acknowledgments)
- [ğŸ‘¤ Author](#-author)

---

## ğŸ”¥ Overview

**LocalMind** is a free, open-source, self-hosted AI platform designed for **students, developers, researchers, and creators** who demand powerful AI capabilities without the constraints of subscriptions, usage limits, or privacy compromises.

### Why LocalMind?

**Traditional AI platforms lock you in with:**
- ğŸ’¸ Monthly subscription fees
- ğŸš« Message and usage limits
- ğŸ” Privacy concerns with data collection
- â˜ï¸ Dependency on cloud services
- ğŸ”’ Vendor lock-in

**LocalMind sets you free with:**
- âœ… **100% Free & Open Source** â€” No hidden costs, ever
- âœ… **Unlimited Usage** â€” No message caps or rate limits
- âœ… **Full Privacy** â€” Your data never leaves your machine
- âœ… **Hybrid Architecture** â€” Mix local and cloud models seamlessly
- âœ… **Custom Training** â€” Teach AI with your own datasets
- âœ… **Global Sharing** â€” Expose your AI to the world instantly
- âœ… **Developer-Friendly** â€” RESTful API for easy integration

### Perfect For

- ğŸ“ **Students** learning AI and machine learning
- ğŸ‘¨â€ğŸ’» **Developers** building AI-powered applications
- ğŸ”¬ **Researchers** conducting experiments with LLMs
- ğŸš€ **Startups** needing custom AI solutions without enterprise costs
- ğŸ¢ **Organizations** requiring private AI infrastructure
- ğŸ¨ **Creators** experimenting with AI-assisted content generation

---

## âœ¨ Features

### ğŸ§  AI Model Support

LocalMind provides a unified interface to interact with both **local** and **cloud-based** AI models:

#### ğŸ–¥ï¸ Local Models (via Ollama)

Run powerful open-source models completely offline:

| Model Family | Description | Use Cases |
|-------------|-------------|-----------|
| **LLaMA** | Meta's flagship open model | General chat, reasoning, coding |
| **Mistral** | High-performance 7B model | Fast responses, efficiency |
| **Phi** | Microsoft's compact model | Edge devices, quick tasks |
| **Gemma** | Google's open model | Balanced performance |
| **Custom Models** | Any Ollama-compatible model | Specialized tasks |

#### â˜ï¸ Cloud Models

Integrate premium AI services when needed:

- **Google Gemini** â€” Advanced reasoning and multimodal
- **OpenAI GPT** â€” Industry-leading language models
- **Groq** â€” Ultra-fast inference speeds
- **RouterAI** â€” Intelligent model routing
- **Coming Soon:** Anthropic Claude, Cohere, AI21 Labs

**Switch between models instantly** â€” No code changes required!

---

### ğŸ“š RAG: Train with Your Own Data

Transform LocalMind into your personal AI expert using **Retrieval-Augmented Generation (RAG)**:

#### Supported Formats

- ğŸ“Š **Excel Files** (.xlsx, .xls) â€” Import spreadsheets directly
- ğŸ“„ **CSV Files** â€” Parse comma-separated datasets
- â“ **Q&A Datasets** â€” Upload question-answer pairs for fine-tuning
- ğŸ”œ **Coming Soon:** PDF, TXT, JSON, and more

#### How It Works

1. **Upload** your documents through the UI
2. **Processing** â€” Automatic text extraction and chunking
3. **Vectorization** â€” Converts data to embeddings
4. **Storage** â€” Creates a private vector database
5. **Querying** â€” AI retrieves relevant context for responses

#### Use Cases

- ğŸ“– Build a chatbot trained on your company's documentation
- ğŸ“ Create a study assistant with your course materials
- ğŸ”¬ Analyze research papers and datasets
- ğŸ’¼ Build internal knowledge bases
- ğŸ“Š Query business data using natural language

**Your data stays 100% local** â€” No cloud uploads, no external storage.

---

### ğŸŒ Global AI Sharing

Share your LocalMind instance with anyone, anywhere:

#### Exposure Methods

| Method | Speed | Custom Domain | Security |
|--------|-------|---------------|----------|
| **LocalTunnel** | Fast | âœ… | Basic |
| **Ngrok** | Fast | âœ… Pro | Advanced |

#### Benefits

- ğŸŒ **Instant Deployment** â€” No server setup required
- ğŸ”— **Shareable URLs** â€” Send links to teammates or clients
- ğŸš€ **Perfect for Demos** â€” Showcase your AI projects
- ğŸ‘¥ **Collaborative Testing** â€” Get feedback from users
- ğŸ“± **Access Anywhere** â€” Use your AI from any device

#### Security Features

- ğŸ” API key authentication
- ğŸš¦ Rate limiting
- ğŸ”’ HTTPS encryption
- ğŸ“Š Usage monitoring

---

### ğŸ”’ Privacy & Security

Your data is yours â€” always.

#### Privacy Guarantees

- ğŸ  **Local Processing** â€” RAG data never leaves your machine
- ğŸ”‘ **Encrypted Storage** â€” API keys stored securely
- ğŸš« **No Telemetry** â€” Zero analytics or tracking
- ğŸ‘ï¸ **Open Source** â€” Audit every line of code
- ğŸ”“ **No Vendor Lock-In** â€” Export data anytime

#### Security Features

- ğŸ›¡ï¸ JWT-based authentication
- ğŸ” Bcrypt password hashing
- ğŸ”’ CORS protection
- ğŸš¦ Rate limiting
- ğŸ“ Request validation
- ğŸ” SQL injection prevention

---

## ğŸš€ Quick Start

Get LocalMind running in under 5 minutes:

```bash
# Clone the repository
git clone https://github.com/NexGenStudioDev/LocalMind.git
cd LocalMind

# Install dependencies
cd server && npm install
cd ../client && npm install

# Start the backend
cd server && npm run dev

# Start the frontend (in a new terminal)
cd client && npm run dev

# Open http://localhost:5173
```

**That's it!** You're ready to chat with AI. ğŸ‰

For detailed setup instructions, see the [Installation Guide](#-installation-guide) below.

---

## ğŸ“¦ Installation Guide

### Prerequisites

Ensure you have the following installed:

| Software | Version | Download |
|----------|---------|----------|
| **Node.js** | 18.x or higher | [nodejs.org](https://nodejs.org/) |
| **npm** | 9.x or higher | Included with Node.js |
| **Git** | Latest | [git-scm.com](https://git-scm.com/) |
| **Ollama** (optional) | Latest | [ollama.ai](https://ollama.ai/) |

#### Verify Installation

```bash
node --version  # Should show v18.x.x or higher
npm --version   # Should show 9.x.x or higher
git --version   # Should show git version 2.x.x
```

---

### 1. Backend Setup

```bash
# Navigate to server directory
cd server

# Install dependencies
npm install

# Create environment file
cp .env.example .env

# Edit .env with your preferred editor
nano .env

# Start development server
npm run dev
```

The backend will be available at `http://localhost:3000`

#### Available Scripts

```bash
npm run dev        # Start development server with hot reload
npm run build      # Compile TypeScript to JavaScript
npm run start      # Run production build
npm run lint       # Check code quality
npm run test       # Run test suite
```

---

### 2. Frontend Setup

```bash
# Navigate to client directory
cd client

# Install dependencies
npm install

# Start development server
npm run dev
```

The frontend will be available at `http://localhost:5173`

#### Available Scripts

```bash
npm run dev        # Start Vite dev server
npm run build      # Build for production
npm run preview    # Preview production build
npm run lint       # Check code quality
npm run type-check # Check TypeScript types
```

---

### 3. Docker (Optional)

Run LocalMind with Docker for simplified deployment:

```bash
# Build and run with Docker Compose
docker-compose up -d

# View logs
docker-compose logs -f

# Stop services
docker-compose down
```

**Docker Compose includes:**
- Node.js backend
- React frontend  
- Nginx reverse proxy
- Volume persistence

---

## âš™ï¸ Configuration

### Environment Variables

Create a `.env` file in the `server` directory:

```env
# Server Configuration
PORT=3000
NODE_ENV=development
ENVIRONMENT=development

# Database
DATABASE_URL=postgresql://user:password@localhost:5432/localmind
MONGO_URI=mongodb://localhost:27017/localmind

# Authentication
LOCALMIND_SECRET=your-super-secret-jwt-key-change-this
JWT_EXPIRATION=7d
REFRESH_TOKEN_EXPIRATION=30d

# AI Configuration
DEFAULT_MODEL=gemini-pro
OLLAMA_HOST=http://localhost:11434

# Cloud AI Provider Keys
GEMINI_API_KEY=your-gemini-api-key-here
OPENAI_API_KEY=your-openai-api-key-here
GROQ_API_KEY=your-groq-api-key-here
ROUTERAI_API_KEY=your-routerai-api-key-here

# RAG Configuration
VECTOR_DB_PATH=./data/vectordb
MAX_FILE_SIZE=50MB
SUPPORTED_FORMATS=.xlsx,.csv,.xls

# Tunnel Configuration
LOCALTUNNEL_SUBDOMAIN=my-localmind
NGROK_AUTHTOKEN=your-ngrok-token-here

# Security
CORS_ORIGIN=http://localhost:5173
RATE_LIMIT_WINDOW=15m
RATE_LIMIT_MAX=100

# Logging
LOG_LEVEL=info
LOG_FILE=./logs/app.log
```

> âš ï¸ **Security Warning:** Never commit `.env` files to version control. Add `.env` to your `.gitignore`.

### Frontend Configuration

Create a `.env` file in the `client` directory:

```env
VITE_API_URL=http://localhost:3000
VITE_APP_NAME=LocalMind
VITE_ENABLE_ANALYTICS=false
```

---

## ğŸ“ Project Structure

```
LocalMind/
â”‚
â”œâ”€â”€ server/                      # Backend application
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ config/             # Configuration files
â”‚   â”‚   â”œâ”€â”€ controllers/        # Request handlers
â”‚   â”‚   â”œâ”€â”€ middleware/         # Express middleware
â”‚   â”‚   â”œâ”€â”€ models/             # Database models
â”‚   â”‚   â”œâ”€â”€ routes/             # API routes
â”‚   â”‚   â”œâ”€â”€ services/           # Business logic
â”‚   â”‚   â”‚   â”œâ”€â”€ ai/            # AI provider integrations
â”‚   â”‚   â”‚   â”œâ”€â”€ rag/           # RAG implementation
â”‚   â”‚   â”‚   â””â”€â”€ tunnel/        # Tunnel services
â”‚   â”‚   â”œâ”€â”€ utils/              # Helper functions
â”‚   â”‚   â”œâ”€â”€ validators/         # Input validation
â”‚   â”‚   â””â”€â”€ index.ts           # Entry point
â”‚   â”œâ”€â”€ tests/                  # Test files
â”‚   â”œâ”€â”€ .env.example           # Environment template
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ tsconfig.json
â”‚
â”œâ”€â”€ client/                      # Frontend application
â”‚   â”œâ”€â”€ public/                 # Static assets
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ assets/            # Images, fonts, etc.
â”‚   â”‚   â”œâ”€â”€ components/        # React components
â”‚   â”‚   â”‚   â”œâ”€â”€ chat/
â”‚   â”‚   â”‚   â”œâ”€â”€ upload/
â”‚   â”‚   â”‚   â””â”€â”€ settings/
â”‚   â”‚   â”œâ”€â”€ hooks/             # Custom React hooks
â”‚   â”‚   â”œâ”€â”€ pages/             # Page components
â”‚   â”‚   â”œâ”€â”€ services/          # API client
â”‚   â”‚   â”œâ”€â”€ store/             # State management
â”‚   â”‚   â”œâ”€â”€ styles/            # CSS/SCSS files
â”‚   â”‚   â”œâ”€â”€ types/             # TypeScript types
â”‚   â”‚   â”œâ”€â”€ utils/             # Helper functions
â”‚   â”‚   â”œâ”€â”€ App.tsx            # Root component
â”‚   â”‚   â””â”€â”€ main.tsx           # Entry point
â”‚   â”œâ”€â”€ .env.example
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ tsconfig.json
â”‚   â””â”€â”€ vite.config.ts
â”‚
â”œâ”€â”€ docs/                        # Documentation
â”œâ”€â”€ scripts/                     # Utility scripts
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .gitignore
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md
```

---

## ğŸ§© API Documentation

### Base URL

```
http://localhost:3000/api/v1
```

### Authentication

All protected endpoints require a JWT token in the Authorization header:

```http
Authorization: Bearer YOUR_JWT_TOKEN
```

---

### ğŸ” Authentication & User Management

#### Register User

```http
POST /api/v1/user/register
Content-Type: application/json

{
  "username": "john_doe",
  "email": "john@example.com",
  "password": "SecurePassword123!"
}
```

**Response:**
```json
{
  "success": true,
  "message": "User registered successfully",
  "data": {
    "userId": "abc123",
    "username": "john_doe",
    "email": "john@example.com",
    "token": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9..."
  }
}
```

#### Login

```http
POST /api/v1/user/login
Content-Type: application/json

{
  "email": "john@example.com",
  "password": "SecurePassword123!"
}
```

#### Get User Profile

```http
GET /api/v1/user/profile
Authorization: Bearer YOUR_JWT_TOKEN
```

#### Update Profile

```http
PUT /api/v1/user/profile
Authorization: Bearer YOUR_JWT_TOKEN
Content-Type: application/json

{
  "username": "john_updated",
  "preferences": {
    "defaultModel": "gemini-pro",
    "theme": "dark"
  }
}
```

---

### âš™ï¸ AI Configuration & API Keys

#### Generate LocalMind API Key

```http
POST /api/v1/user/local-mind-api-key-generator
Authorization: Bearer YOUR_JWT_TOKEN
Content-Type: application/json

{
  "name": "Production API Key",
  "permissions": ["chat", "upload", "train"]
}
```

**Response:**
```json
{
  "success": true,
  "data": {
    "apiKey": "lm_1234567890abcdef",
    "name": "Production API Key",
    "createdAt": "2024-01-15T10:30:00Z"
  }
}
```

#### List API Keys

```http
GET /api/v1/user/local-mind-api-keys
Authorization: Bearer YOUR_JWT_TOKEN
```

#### Delete API Key

```http
DELETE /api/v1/user/local-mind-api-keys/:keyId
Authorization: Bearer YOUR_JWT_TOKEN
```

#### Get AI Configuration

```http
GET /api/v1/user/ai-config
Authorization: Bearer YOUR_JWT_TOKEN
```

#### Update AI Configuration

```http
PUT /api/v1/user/ai-config
Authorization: Bearer YOUR_JWT_TOKEN
Content-Type: application/json

{
  "providers": {
    "gemini": {
      "enabled": true,
      "apiKey": "your-gemini-key"
    },
    "ollama": {
      "enabled": true,
      "host": "http://localhost:11434"
    }
  },
  "defaultModel": "gemini-pro"
}
```

---

### ğŸ’¬ Chat & Messaging

#### Send Message

```http
POST /api/v1/chat/send-message
Authorization: Bearer YOUR_JWT_TOKEN
Content-Type: application/json

{
  "message": "What is quantum computing?",
  "model": "gemini-pro",
  "conversationId": "conv_123",
  "useRAG": true
}
```

**Response:**
```json
{
  "success": true,
  "data": {
    "messageId": "msg_456",
    "response": "Quantum computing is...",
    "model": "gemini-pro",
    "timestamp": "2024-01-15T10:30:00Z",
    "tokensUsed": 245
  }
}
```

#### Stream Message (SSE)

```http
POST /api/v1/chat/stream
Authorization: Bearer YOUR_JWT_TOKEN
Content-Type: application/json

{
  "message": "Write a poem about AI",
  "model": "gpt-4"
}
```

#### Get Chat History

```http
GET /api/v1/chat/history?conversationId=conv_123&limit=50
Authorization: Bearer YOUR_JWT_TOKEN
```

#### Create New Conversation

```http
POST /api/v1/chat/conversation
Authorization: Bearer YOUR_JWT_TOKEN
Content-Type: application/json

{
  "title": "Project Discussion",
  "model": "gemini-pro"
}
```

#### Delete Conversation

```http
DELETE /api/v1/chat/conversation/:conversationId
Authorization: Bearer YOUR_JWT_TOKEN
```

---

### ğŸ“š File Upload & RAG Training

#### Upload Excel/CSV

```http
POST /api/v1/upload/excel
Authorization: Bearer YOUR_JWT_TOKEN
Content-Type: multipart/form-data

file: [your-file.xlsx]
name: "Sales Data Q4"
description: "Quarterly sales figures"
```

**Response:**
```json
{
  "success": true,
  "data": {
    "fileId": "file_789",
    "name": "Sales Data Q4",
    "size": 2048576,
    "rowCount": 1500,
    "status": "processing"
  }
}
```

#### Upload Q&A Dataset

```http
POST /api/v1/upload/dataSet
Authorization: Bearer YOUR_JWT_TOKEN
Content-Type: application/json

{
  "name": "FAQ Dataset",
  "questions": [
    {
      "question": "What is LocalMind?",
      "answer": "LocalMind is an open-source AI platform..."
    }
  ]
}
```

#### Train Model with Uploaded Data

```http
POST /api/v1/train/upload
Authorization: Bearer YOUR_JWT_TOKEN
Content-Type: application/json

{
  "fileId": "file_789",
  "chunkSize": 500,
  "overlapSize": 50
}
```

#### Get Upload Status

```http
GET /api/v1/upload/status/:fileId
Authorization: Bearer YOUR_JWT_TOKEN
```

#### List Uploaded Files

```http
GET /api/v1/upload/files
Authorization: Bearer YOUR_JWT_TOKEN
```

#### Delete Uploaded File

```http
DELETE /api/v1/upload/files/:fileId
Authorization: Bearer YOUR_JWT_TOKEN
```

---

### ğŸŒ Public Exposure

#### Expose via LocalTunnel

```http
POST /api/v1/expose/localtunnel
Authorization: Bearer YOUR_JWT_TOKEN
Content-Type: application/json

{
  "subdomain": "my-awesome-ai",
  "port": 3000
}
```

**Response:**
```json
{
  "success": true,
  "data": {
    "url": "https://my-awesome-ai.loca.lt",
    "status": "active"
  }
}
```

#### Expose via Ngrok

```http
POST /api/v1/expose/ngrok
Authorization: Bearer YOUR_JWT_TOKEN
Content-Type: application/json

{
  "authToken": "your-ngrok-token",
  "domain": "myapp.ngrok.io"
}
```

#### Get Exposure Status

```http
GET /api/v1/expose/status
Authorization: Bearer YOUR_JWT_TOKEN
```

#### Stop Exposure

```http
DELETE /api/v1/expose/stop
Authorization: Bearer YOUR_JWT_TOKEN
```

---

### ğŸ“Š Analytics & Monitoring

#### Get Usage Statistics

```http
GET /api/v1/analytics/usage
Authorization: Bearer YOUR_JWT_TOKEN
```

#### Get Model Performance

```http
GET /api/v1/analytics/models
Authorization: Bearer YOUR_JWT_TOKEN
```

---

## ğŸ’¡ Usage Examples

### Example 1: Basic Chat

```javascript
// Initialize client
const API_URL = 'http://localhost:3000/api/v1';
const token = 'your-jwt-token';

// Send message
const response = await fetch(`${API_URL}/chat/send-message`, {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
    'Authorization': `Bearer ${token}`
  },
  body: JSON.stringify({
    message: 'Explain machine learning in simple terms',
    model: 'gemini-pro'
  })
});

const data = await response.json();
console.log(data.data.response);
```

### Example 2: Upload and Train with Custom Data

```javascript
// Upload Excel file
const formData = new FormData();
formData.append('file', fileInput.files[0]);
formData.append('name', 'Company Knowledge Base');

const uploadResponse = await fetch(`${API_URL}/upload/excel`, {
  method: 'POST',
  headers: {
    'Authorization': `Bearer ${token}`
  },
  body: formData
});

const { data: { fileId } } = await uploadResponse.json();

// Train model with uploaded data
const trainResponse = await fetch(`${API_URL}/train/upload`, {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
    'Authorization': `Bearer ${token}`
  },
  body: JSON.stringify({
    fileId,
    chunkSize: 500
  })
});

// Use RAG-enhanced chat
const chatResponse = await fetch(`${API_URL}/chat/send-message`, {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
    'Authorization': `Bearer ${token}`
  },
  body: JSON.stringify({
    message: 'What does our policy say about remote work?',
    useRAG: true
  })
});
```

### Example 3: Streaming Responses

```javascript
const eventSource = new EventSource(
  `${API_URL}/chat/stream?token=${token}&message=Write a story about AI`
);

eventSource.onmessage = (event) => {
  const chunk = JSON.parse(event.data);
  console.log(chunk.content); // Display chunk in real-time
};

eventSource.onerror = () => {
  eventSource.close();
};
```

### Example 4: Expose Your AI Globally

```javascript
// Start LocalTunnel
const exposeResponse = await fetch(`${API_URL}/expose/localtunnel`, {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
    'Authorization': `Bearer ${token}`
  },
  body: JSON.stringify({
    subdomain: 'my-ai-demo'
  })
});

const { data: { url } } = await exposeResponse.json();
console.log(`Your AI is now accessible at: ${url}`);
```

---

## ğŸ› ï¸ Tech Stack

### Backend

| Technology | Purpose | Version |
|-----------|---------|---------|
| **Node.js** | Runtime environment | 18+ |
| **Express** | Web framework | 4.x |
| **TypeScript** | Type safety | 5.x |
| **Prisma / MongoDB** | Database ORM | Latest |
| **JWT** | Authentication | Latest |
| **Multer** | File uploads | Latest |
| **LangChain** | RAG implementation | Latest |
| **Ollama SDK** | Local LLM integration | Latest |

### Frontend

| Technology | Purpose | Version |
|-----------|---------|---------|
| **React** | UI framework | 18+ |
| **TypeScript** | Type safety | 5.x |
| **Vite** | Build tool | 5.x |
| **TailwindCSS** | Styling | 3.x |
| **Zustand** | State management | Latest |
| **React Query** | Data fetching | Latest |
| **React Router** | Navigation | 6.x |
| **Axios** | HTTP client | Latest |

### AI & ML

- **Ollama** â€” Local LLM runtime
- **LangChain** â€” RAG framework
- **Vector Databases** â€” Embeddings storage
- **Google Gemini SDK**
- **OpenAI SDK**
- **Groq SDK**

---

## ğŸ”§ Troubleshooting

### Common Issues

#### 1. Backend Won't Start

**Problem:** `Error: Cannot find module 'express'`

**Solution:**
```bash
cd server
rm -rf node_modules package-lock.json
npm install
npm run dev
```

#### 2. Ollama Connection Failed

**Problem:** `Error: ECONNREFUSED localhost:11434`

**Solution:**
- Ensure Ollama is installed and running: `ollama serve`
- Check Ollama status: `ollama list`
- Verify OLLAMA_HOST in `.env`

#### 3. File Upload Fails

**Problem:** `Error: File size exceeds limit`

**Solution:**
- Check MAX_FILE_SIZE in `.env`
- Increase the limit if needed
- Compress large files before uploading

#### 4. RAG Not Working

**Problem:** AI doesn't use uploaded data

**Solution:**
- Verify file was processed: `GET /api/v1/upload/status/:fileId`
- Ensure `useRAG: true` in chat request
- Check vector database path in `.env`

#### 5. CORS Errors

**Problem:** `Access-Control-Allow-Origin` error

**Solution:**
- Update CORS_ORIGIN in server `.env`
- Restart backend server
- Check frontend URL matches CORS_ORIGIN

---

## ğŸ—ºï¸ Roadmap

### Version 1.1 (Q2 2024)

- [ ] PDF and TXT file support for RAG
- [ ] Multi-language support
- [ ] Dark/Light theme toggle
- [ ] Voice input/output
- [ ] Mobile-responsive design improvements

### Version 1.2 (Q3 2024)

- [ ] Anthropic Claude integration
- [ ] Image generation support
- [ ] Code execution sandbox
- [ ] Collaborative chat sessions
- [ ] Advanced analytics dashboard

### Version 2.0 (Q4 2024)

- [ ] Plugin system for extensions
- [ ] Marketplace for custom models
- [ ] Enterprise features (SSO, RBAC)
- [ ] Kubernetes deployment support
- [ ] Multi-user workspaces

### Community Requests

- [ ] WhatsApp/Telegram bot integration
- [ ] Markdown export for conversations
- [ ] Custom model fine-tuning UI
- [ ] Blockchain-based API key management

**Want to suggest a feature?** [Open an issue](https://github.com/NexGenStudioDev/LocalMind/issues) or join our [Discord community](#)!

---

## ğŸ¤ Contributing

We â¤ï¸ contributions! Here's how you can help:

### Ways to Contribute

- ğŸ› **Report bugs** â€” Found a bug? [Open an issue](https://github.com/NexGenStudioDev/LocalMind/issues)
- ğŸ’¡ **Suggest features** â€” Have ideas? Share them!
- ğŸ“ **Improve docs** â€” Help others understand LocalMind
- ğŸ”§ **Submit PRs** â€” Fix bugs or add features
- ğŸŒ **Translate** â€” Make LocalMind accessible worldwide
- â­ **Star the repo** â€” Show your support!

### Development Workflow

1. **Fork the repository**
   ```bash
   # Click "Fork" on GitHub, then:
   git clone https://github.com/YOUR_USERNAME/LocalMind.git
   cd LocalMind
   ```

2. **Create a feature branch**
   ```bash
   git checkout -b feature/amazing-feature
   ```

3. **Make your changes**
   - Follow TypeScript best practices
   - Write clean, documented code
   - Add tests for new features
   - Update documentation

4. **Test your changes**
   ```bash
   npm run test
   npm run lint
   npm run type-check
   ```

5. **Commit with conventional commits**
   ```bash
   git commit -m "feat: add amazing feature"
   git commit -m "fix: resolve bug in chat"
   git commit -m "docs: update API documentation"
   ```

6. **Push and create PR**
   ```bash
   git push origin feature/amazing-feature
   # Then open a Pull Request on GitHub
   ```

### Commit Message Guidelines

We follow [Conventional Commits](https://www.conventionalcommits.org/):

- `feat:` â€” New feature
- `fix:` â€” Bug fix
- `docs:` â€” Documentation changes
- `style:` â€” Code style changes (formatting, etc.)
- `refactor:` â€” Code refactoring
- `test:` â€” Adding or updating tests
- `chore:` â€” Build process or auxiliary tool changes

### Code Style

- **TypeScript** â€” Use strict typing, avoid `any`
- **ESLint** â€” Follow configured rules
- **Prettier** â€” Auto-format on save
- **Naming** â€” Use camelCase for variables, PascalCase for components
- **Comments** â€” Document complex logic

### Pull Request Process

1. Update README.md with details of changes if needed
2. Update the documentation with new API endpoints
3. Add tests for new functionality
4. Ensure all tests pass
5. Request review from maintainers
6. Address review feedback
7. Squash commits before merging

### Community Guidelines

- Be respectful and inclusive
- Provide constructive feedback
- Help newcomers get started
- Follow our [Code of Conduct](CODE_OF_CONDUCT.md)

---

## ğŸ“„ License

This project is licensed under the **MIT License** â€” see the [LICENSE](LICENSE) file for details.

### What This Means

âœ… **Commercial use** â€” Use LocalMind in commercial projects  
âœ… **Modification** â€” Modify the code as you see fit  
âœ… **Distribution** â€” Share LocalMind with others  
âœ… **Private use** â€” Use it privately in your organization  

âš ï¸ **Limitation of liability** â€” Use at your own risk  
âš ï¸ **No warranty** â€” Provided "as is"  

**Attribution appreciated but not required!** If you build something cool with LocalMind, let us know â€” we'd love to feature it!

---

## ğŸ™ Acknowledgments

LocalMind stands on the shoulders of giants. Huge thanks to:

### Open Source Projects

- **[Ollama](https://ollama.ai/)** â€” Making local LLMs accessible
- **[LangChain](https://langchain.com/)** â€” Powering our RAG implementation
- **[React](https://reactjs.org/)** â€” Building amazing UIs
- **[Vite](https://vitejs.dev/)** â€” Lightning-fast build tool
- **[Express](https://expressjs.com/)** â€” Reliable backend framework

### AI Providers

- **Google** â€” Gemini API
- **OpenAI** â€” GPT models
- **Meta** â€” LLaMA models
- **Mistral AI** â€” Open models
- **Groq** â€” Fast inference

### Community

- All our [contributors](https://github.com/NexGenStudioDev/LocalMind/graphs/contributors)
- Everyone who reported bugs and suggested features
- The open-source community for inspiration

### Special Thanks

- **Students and educators** using LocalMind for learning
- **Developers** building amazing apps with our API
- **Contributors** who helped improve the codebase
- **You** for choosing LocalMind! ğŸ‰

---

## ğŸ‘¤ Author

**NexGenStudioDev**

### Connect With Us

- ğŸŒ **Website:** [Coming Soon]
- ğŸ’¼ **GitHub:** [@NexGenStudioDev](https://github.com/NexGenStudioDev)
- ğŸ¦ **Twitter:** [Coming Soon]
- ğŸ’¬ **Discord:** [Join our community](#)
- ğŸ“§ **Email:** support@localmind.ai

### Support the Project

If LocalMind has been helpful to you:

- â­ **Star this repository** on GitHub
- ğŸ¦ **Share it** on social media
- ğŸ“ **Write about it** on your blog
- ğŸ’° **Sponsor development** (Coming Soon)
- ğŸ¤ **Contribute code** or documentation

---

## ğŸ“Š Project Stats

![GitHub stars](https://img.shields.io/github/stars/NexGenStudioDev/LocalMind?style=social)
![GitHub forks](https://img.shields.io/github/forks/NexGenStudioDev/LocalMind?style=social)
![GitHub issues](https://img.shields.io/github/issues/NexGenStudioDev/LocalMind)
![GitHub pull requests](https://img.shields.io/github/issues-pr/NexGenStudioDev/LocalMind)
![GitHub license](https://img.shields.io/github/license/NexGenStudioDev/LocalMind)

---

## ğŸ¯ Support

### Getting Help

- ğŸ“– **Documentation:** Read our [full docs](#)
- ğŸ’¬ **Discord:** Join our [community server](#)
- ğŸ› **Bug Reports:** [Open an issue](https://github.com/NexGenStudioDev/LocalMind/issues)
- ğŸ’¡ **Feature Requests:** [Suggest features](https://github.com/NexGenStudioDev/LocalMind/discussions)
- ğŸ“§ **Email:** support@localmind.ai

### FAQ

**Q: Is LocalMind really free?**  
A: Yes! 100% free and open-source. No hidden costs, no premium tiers, no subscriptions.

**Q: Can I use LocalMind commercially?**  
A: Absolutely! The MIT license allows commercial use.

**Q: Do I need a GPU for local models?**  
A: Recommended but not required. Ollama works on CPU, but GPU speeds things up significantly.

**Q: How much disk space do I need?**  
A: Base installation: ~500MB. Each Ollama model: 2-7GB depending on size.

**Q: Can I deploy LocalMind to production?**  
A: Yes! Use Docker for easy deployment. See our [deployment guide](#).

**Q: Is my data secure?**  
A: Yes. RAG data stays on your machine. API keys are encrypted. No telemetry or tracking.

**Q: Can I contribute without coding?**  
A: Yes! Help with documentation, translations, bug reports, or spread the word.

---

<div align="center">
  <br/>
  <h3>ğŸš€ LocalMind â€” Free, Private, Limitless AI for Everyone</h3>
  <p>Built with â¤ï¸ by the open-source community</p>
  <br/>
  
  **[Get Started](#-quick-start)** â€¢ **[Documentation](#)** â€¢ **[Join Community](#)** â€¢ **[Report Bug](https://github.com/NexGenStudioDev/LocalMind/issues)**
  
  <br/>
  
  <sub>If you find LocalMind useful, please consider giving it a â­ï¸ on GitHub!</sub>
</div>

---

## ğŸ“ Changelog

### [v1.0.0] - 2024-01-15

#### Added
- ğŸ‰ Initial release of LocalMind
- ğŸ§  Support for Ollama local models
- â˜ï¸ Cloud AI integrations (Gemini, OpenAI, Groq, RouterAI)
- ğŸ“š RAG with Excel/CSV uploads
- ğŸŒ LocalTunnel and Ngrok support
- ğŸ” JWT authentication
- ğŸ’¬ Real-time chat interface
- ğŸ“Š Usage analytics
- ğŸ¨ Modern React UI with Tailwind CSS

#### Security
- Implemented bcrypt password hashing
- Added CORS protection
- Rate limiting for API endpoints
- Input validation and sanitization

---

<div align="center">
  <br/>
  <p>Made with âš¡ by <b>NexGenStudioDev</b></p>
  <p>
    <a href="#-overview">Back to top â†‘</a>
  </p>
</div>